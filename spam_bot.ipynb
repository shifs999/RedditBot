{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af24866f-f9ee-4502-aa71-e828136e60de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import random\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b16575e2-fbf1-439f-b62e-5572a889b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "common_spammy_words = ['udemy', 'course', 'save', 'coupon', 'free', 'discount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57b5589-c489-435f-9150-2b8d6a8ed918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShifsBot1\n"
     ]
    }
   ],
   "source": [
    "reddit = praw.Reddit(client_id = 'CLIENT_ID',\n",
    "                     client_secret = 'CLIENT_SECRET',\n",
    "                     username = 'USERNAME',\n",
    "                     password = 'PASSWORD',\n",
    "                     user_agent = 'AGENT')\n",
    "\n",
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "117d8ad3-f202-49d9-a4d0-4e44ef07ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spam_by_name(search_query):\n",
    "    authors = []\n",
    "    for submission in reddit.subreddit(\"all\").search(search_query, sort=\"new\", limit=11):\n",
    "        print(submission.title, submission.author, submission.url)\n",
    "        if submission.author not in authors:\n",
    "            authors.append(submission.author)\n",
    "    return authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05943782-65c4-4133-b7c6-3bdc235a4c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taskbar misaligned or inappropriate; reboot or restart doesnt help. sivvaaaaaaah https://i.redd.it/gg0mc068z63e1.png\n",
      "I wanna increase my knowledge in robotics and hopefully turn it into a job nichonichot https://www.reddit.com/r/robotics/comments/1h05iox/i_wanna_increase_my_knowledge_in_robotics_and/\n",
      "Advance Your Career: 100 Free Courses with Certificates on Udemy  courzeorg /r/Udemy/comments/1h05dfk/advance_your_career_100_free_courses_with/\n",
      "Advance Your Career: 100 Free Courses with Certificates on Udemy  courzeorg https://www.reddit.com/r/Udemy/comments/1h05dfk/advance_your_career_100_free_courses_with/\n",
      "Pmpfocus review please. whitehawk04 https://www.reddit.com/r/pmp/comments/1h044o8/pmpfocus_review_please/\n",
      "Share Your Non-CS Journey: Learning DSA - We Want to Hear Your Story (non-cs major, USA) ThinkingVincent https://www.reddit.com/r/SurveyExchange/comments/1h03n5e/share_your_noncs_journey_learning_dsa_we_want_to/\n",
      "Share Your Non-CS Journey: Learning DSA - We Want to Hear Your Story (non-cs major, USA) ThinkingVincent https://www.reddit.com/r/SampleSize/comments/1h03ko3/share_your_noncs_journey_learning_dsa_we_want_to/\n",
      "New Beatboxer...Not sure how this guy is getting these tones National-Command614 https://www.reddit.com/r/beatbox/comments/1h02mht/new_beatboxernot_sure_how_this_guy_is_getting/\n",
      "Life Résumé Writing Course (5.0 stars) - Seeking inspiration or exploring a new direction in life? liferesumecourse https://www.reddit.com/r/udemyfreebies/comments/1h026oi/life_résumé_writing_course_50_stars_seeking/\n",
      "Neil Anderson's CCNA Gold Bootcamp Is $50 OFF with Black Friday Sale ampankajsharma https://www.reddit.com/r/ccna/comments/1h025gt/neil_andersons_ccna_gold_bootcamp_is_50_off_with/\n",
      "Live Project on Google Cloud tryonce1980 https://www.reddit.com/r/googlecloud/comments/1h024i7/live_project_on_google_cloud/\n",
      "User sivvaaaaaaah trashy score is: 0.0\n",
      "User nichonichot trashy score is: 0.0\n",
      "User courzeorg trashy score is: 1.0\n",
      "User whitehawk04 trashy score is: 0.0\n",
      "User ThinkingVincent trashy score is: 0.0\n",
      "User National-Command614 trashy score is: 0.0\n",
      "User liferesumecourse trashy score is: 1.0\n",
      "User ampankajsharma trashy score is: 0.35\n",
      "User tryonce1980 trashy score is: 0.0\n",
      "*Beep boop*\n",
      "\n",
      "I am a bot that sniffs out spammers, and this smells like spam.\n",
      "\n",
      "At least 100.0% out of the 100 submissions from /u/courzeorg appear to be for Udemy affiliate links. \n",
      "\n",
      "Don't let spam take over Reddit! Throw it out!\n",
      "\n",
      "*Bee bop*\n",
      "We've posted to https://reddit.com/r/udemyfreebies/comments/1h05dla/advance_your_career_100_free_courses_with/ and now we need to sleep for 12 minutes\n",
      "taskbar misaligned or inappropriate; reboot or restart doesnt help. sivvaaaaaaah https://i.redd.it/gg0mc068z63e1.png\n",
      "I wanna increase my knowledge in robotics and hopefully turn it into a job nichonichot https://www.reddit.com/r/robotics/comments/1h05iox/i_wanna_increase_my_knowledge_in_robotics_and/\n",
      "Advance Your Career: 100 Free Courses with Certificates on Udemy  courzeorg /r/Udemy/comments/1h05dfk/advance_your_career_100_free_courses_with/\n",
      "Advance Your Career: 100 Free Courses with Certificates on Udemy  courzeorg https://www.reddit.com/r/Udemy/comments/1h05dfk/advance_your_career_100_free_courses_with/\n",
      "Pmpfocus review please. whitehawk04 https://www.reddit.com/r/pmp/comments/1h044o8/pmpfocus_review_please/\n",
      "Share Your Non-CS Journey: Learning DSA - We Want to Hear Your Story (non-cs major, USA) ThinkingVincent https://www.reddit.com/r/SurveyExchange/comments/1h03n5e/share_your_noncs_journey_learning_dsa_we_want_to/\n",
      "Share Your Non-CS Journey: Learning DSA - We Want to Hear Your Story (non-cs major, USA) ThinkingVincent https://www.reddit.com/r/SampleSize/comments/1h03ko3/share_your_noncs_journey_learning_dsa_we_want_to/\n",
      "New Beatboxer...Not sure how this guy is getting these tones National-Command614 https://www.reddit.com/r/beatbox/comments/1h02mht/new_beatboxernot_sure_how_this_guy_is_getting/\n",
      "Life Résumé Writing Course (5.0 stars) - Seeking inspiration or exploring a new direction in life? liferesumecourse https://www.reddit.com/r/udemyfreebies/comments/1h026oi/life_résumé_writing_course_50_stars_seeking/\n",
      "Neil Anderson's CCNA Gold Bootcamp Is $50 OFF with Black Friday Sale ampankajsharma https://www.reddit.com/r/ccna/comments/1h025gt/neil_andersons_ccna_gold_bootcamp_is_50_off_with/\n",
      "Live Project on Google Cloud tryonce1980 https://www.reddit.com/r/googlecloud/comments/1h024i7/live_project_on_google_cloud/\n",
      "User sivvaaaaaaah trashy score is: 0.0\n",
      "User nichonichot trashy score is: 0.0\n",
      "User courzeorg trashy score is: 1.0\n",
      "User whitehawk04 trashy score is: 0.0\n",
      "User ThinkingVincent trashy score is: 0.0\n",
      "User National-Command614 trashy score is: 0.0\n",
      "User liferesumecourse trashy score is: 1.0\n",
      "User ampankajsharma trashy score is: 0.35\n",
      "User tryonce1980 trashy score is: 0.0\n",
      "This submission has already been tagged.\n",
      "This submission has already been tagged.\n",
      "This submission has already been tagged.\n",
      "*Beep boop*\n",
      "\n",
      "I am a bot that sniffs out spammers, and this smells like spam.\n",
      "\n",
      "At least 100.0% out of the 100 submissions from /u/courzeorg appear to be for Udemy affiliate links. \n",
      "\n",
      "Don't let spam take over Reddit! Throw it out!\n",
      "\n",
      "*Bee bop*\n",
      "We've posted to https://reddit.com/r/Udemy/comments/1h05dfk/advance_your_career_100_free_courses_with/ and now we need to sleep for 12 minutes\n"
     ]
    }
   ],
   "source": [
    "DEBUG_MODE = False\n",
    "debug_posted = []\n",
    "\n",
    "while True:\n",
    "    current_search_query = random.choice([\"udemy\"])\n",
    "    spam_content = []\n",
    "    trashy_users = {}\n",
    "    smelly_authors = find_spam_by_name(current_search_query)\n",
    "    for author in smelly_authors:\n",
    "        user_trashy_urls = [] # Tracks submissions flagged as spam for this user\n",
    "        sub_count = 0 #Total submissions analyzed for this user.\n",
    "        dirty_count = 0 #Number of spammy submissions for this user.\n",
    "        try:\n",
    "            for sub in reddit.redditor(str(author)).submissions.new(): #for each submission by the author\n",
    "                submit_links_to = sub.url #The URL of the submission.\n",
    "                submit_id = sub.id #Unique submission ID.\n",
    "                submit_subreddit = sub.subreddit #Subreddit where the submission was posted.\n",
    "                submit_title = sub.title #Title of the submission.\n",
    "                dirty = False\n",
    "                for regex in common_spammy_words:\n",
    "                    #Searches the title against a list of common spam indicators using regex.\n",
    "                    if re.search(regex, submit_title.lower()):\n",
    "                        dirty = True\n",
    "                        junk = [submit_id,submit_title]\n",
    "                        if junk not in user_trashy_urls:\n",
    "                            user_trashy_urls.append([submit_id,submit_title,str(author)])\n",
    "                if dirty:\n",
    "                    dirty_count += 1\n",
    "                sub_count += 1\n",
    "                \n",
    "            try:\n",
    "                trashy_score = dirty_count/sub_count\n",
    "            except: trashy_score = 0.0\n",
    "            print(\"User {} trashy score is: {}\".format(str(author), round(trashy_score,3)))\n",
    "\n",
    "            #If the spam score is 50% or higher and the user has posted more than one submission, they are added to trashy_users with their spam score and total submissions.\n",
    "            if trashy_score >= 0.5 and sub_count > 1:\n",
    "                trashy_users[str(author)] = [trashy_score,sub_count]\n",
    "\n",
    "                for trash in user_trashy_urls:\n",
    "                    spam_content.append(trash)  \n",
    "\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "\n",
    "    for spam in spam_content:\n",
    "        spam_id = spam[0]\n",
    "        spam_user = spam[2]\n",
    "        submission = reddit.submission(id=spam[0])\n",
    "        created_time = submission.created_utc\n",
    "        tagged = False\n",
    "\n",
    "        for comment in submission.comments.list():\n",
    "            comment_text = comment.body\n",
    "            if \"*Beep boop*\" in comment_text:\n",
    "                print(\"This submission has already been tagged.\")\n",
    "                tagged = True\n",
    "\n",
    "        if tagged:\n",
    "            continue\n",
    "\n",
    "        if time.time()-created_time <= 86400:\n",
    "            link = \"https://reddit.com\"+submission.permalink\n",
    "\n",
    "            message = \"\"\"*Beep boop*\n",
    "\n",
    "I am a bot that sniffs out spammers, and this smells like spam.\n",
    "\n",
    "At least {}% out of the {} submissions from /u/{} appear to be for Udemy affiliate links. \n",
    "\n",
    "Don't let spam take over Reddit! Throw it out!\n",
    "\n",
    "*Bee bop*\"\"\".format(round(trashy_users[spam_user][0]*100,2), trashy_users[spam_user][1], spam_user)\n",
    "            try:\n",
    "                if DEBUG_MODE:\n",
    "                    if link in debug_posted:\n",
    "                        continue\n",
    "                    print(f\"Would've posted reply to post by {spam_user}: {link}\")\n",
    "                    debug_posted.append(link)\n",
    "                    continue\n",
    "\n",
    "                with open(\"posted_urls.txt\",\"r\") as f:\n",
    "                    already_posted = f.read().split('\\n')\n",
    "                if link not in already_posted:\n",
    "                    print(message)\n",
    "                    submission.reply(message)\n",
    "                    print(\"We've posted to {} and now we need to sleep for 12 minutes\".format(link))\n",
    "                    with open(\"posted_urls.txt\",\"a\") as f:\n",
    "                        f.write(link+'\\n')\n",
    "                    time.sleep(12*60)\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(str(e))\n",
    "                time.sleep(12*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c56823a-3b32-4cbc-84d4-954ec788dabd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
